{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# RLTK Notebook\n",
    "\n",
    "Here's the notebook of RLTK.\n",
    "\n",
    "Useful links:\n",
    "- [Github Repository](https://github.com/usc-isi-i2/rltk)\n",
    "- [Documents](http://rltk.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Installation\n",
    "\n",
    "1. Get RLTK from Github (it will be uploaded to PyPI later)\n",
    "```\n",
    "git clone https://github.com/usc-isi-i2/rltk.git\n",
    "```\n",
    "2. Install the dependencies.\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "3. For testing purpose, install [pytest](http://doc.pytest.org/en/latest/) and run test cases.\n",
    "```\n",
    "python -m pytest\n",
    "```\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "Let's start with a simple example. If you want to compute the Levenshtein Distance between two sequences, initialize RLTK and invoke measurement. All the files used in examples can be found in `examples` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this two lines are just for locating the package.\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import rltk\n",
    "tk = rltk.init()\n",
    "tk.levenshtein_distance('a', 'abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "For similarity measurements, RLTK supports `distance` and `similarity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.levenshtein_similarity('a', 'abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Some of the methods need extra resources. In RLTK, you can simple load it and give it a name, then told RLTK which resource you want to use when invoking methods. This example shows how to compute the customized weighted Levenshetin Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edit_distance_cost = {'insert': {'c':50}, 'insert_default':100, 'delete_default':100, 'substitute_default':100}\n",
    "\n",
    "tk.load_edit_distance_table('A1', edit_distance_cost)\n",
    "tk.levenshtein_distance('a', 'abc', name='A1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a method needs file path as input, it can be absolute or relative. For relative path, RLTK will get this file in `root_path`. Use `set_root_path` to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zege/ISI/rltk/examples'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.set_root_path('../examples')\n",
    "tk.get_root_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can also load resources from files, like `load_df_corpus`. In text file, each line has some tokens separatedd by whitespace. RLTK will treat each line as a document. [Example file: [df_corpus_1.txt](df_corpus_1.txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17541160386140583"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.load_df_corpus('B1', 'df_corpus_1.txt', file_type='text', mode='append')\n",
    "tk.tf_idf_similarity(['a', 'b', 'a'], ['a', 'c','d','f'], name='B1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For `load_df_corpus`, RLTK also support loading Json Line file (each line is a Json object). `json_path` is used to extract the field(s) as document. [Example file: [jl_file_1.jsonl](jl_file_1.jsonl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8944271909999159"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.load_df_corpus('B2', 'jl_file_1.jsonl', file_type='json_lines', json_path='desc[*]', mode='append')\n",
    "tk.tf_idf_similarity(['abc'], ['abc', 'def'], name='B2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Make sure using the corresponding resource type or it will cause an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid name or type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2b969af0a19d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlevenshtein_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'B1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/zege/ISI/rltk/rltk/core.pyc\u001b[0m in \u001b[0;36mlevenshtein_similarity\u001b[0;34m(self, s1, s2, name)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlevenshtein_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'edit_distance_table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0minsert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'insert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zege/ISI/rltk/rltk/core.pyc\u001b[0m in \u001b[0;36m_has_resource\u001b[0;34m(self, name, type)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rs_dict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rs_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid name or type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_valid_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid name or type"
     ]
    }
   ],
   "source": [
    "tk.levenshtein_similarity('a', 'abc', name='B1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Compute Feature Vector\n",
    "\n",
    "Let's get involved. Now you have the following json dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "j1 = {'id': 1, 'name': 'abc', 'gender': 'male'}\n",
    "j2 = {'id': '2','name': 'bcd', 'gender': 'male'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You want to compute a feature vector from different fields with different feature functions, you can load a configuration file [Example file: [feature_config_1.json](feature_config_1.json)] and invoke `compute_feature_vector`. The complete configuration explaination can be found [here](http://rltk.readthedocs.io/en/latest/rltk.html#core.Core.load_feature_configuration). In config file, you can define the id of entity, the way of handling exception and the feature functions and its parameters (the field name start with a `_` is a comment which will be ignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_vector': [0.33333333333333337, 1.0], 'id': [1, '2']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.load_feature_configuration('C1', 'feature_config_1.json')\n",
    "tk.compute_feature_vector(j1, j2, name='C1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classification\n",
    "\n",
    "After getting feature vectors, you can featurized these vectors by ground truth. [Example files: [feature_config_1.json](feature_file_1.jsonl), [ground_truth_1.jsonl](ground_truth_1.jsonl)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'id': [3, 4], u'feature_vector': [0.3, 0.4], 'label': 0.8}\n"
     ]
    }
   ],
   "source": [
    "tk.featurize_ground_truth('feature_file_1.jsonl', 'ground_truth_1.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If there's no `output_file_path` set, the result will print to STDOUT.\n",
    "\n",
    "When featurized ground truth is generated, supervised learning can be used to train classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "featurized_ground_truth = [\n",
    "    {'feature_vector': [0, 0], 'label': [0], 'id': [1, 2]},\n",
    "    {'feature_vector': [1, 1], 'label': [1], 'id': [3, 4]}\n",
    "]\n",
    "model = tk.train_classifier(featurized_ground_truth, config={'function': 'svm'})\n",
    "print model.predict([[2., 2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Performance Optimization\n",
    "\n",
    "For some of the large data set, there are many duplicated calculation. For TF/IDF, RLTK supports to pre-compute Term Frequency and Inverse Document Frequency. It is extremely useful to compute similarities in those pairwised data.\n",
    "\n",
    "```python\n",
    "\n",
    "# load test data and initialize rltk\n",
    "...\n",
    "\n",
    "# compute and cache tf\n",
    "cached_tf = []\n",
    "for i in test_data:\n",
    "    cached_tf.append(tk.compute_tf(i))\n",
    "    \n",
    "# compute idf\n",
    "tk.compute_idf('corpus_wc', new_name='corpus_wc_cached', math_log=True)\n",
    "\n",
    "# compute similarity\n",
    "for i in range(total):\n",
    "   for j in range(total):\n",
    "       tk.cached_tf_idf_similarity(\n",
    "           test_data[i], test_data[j], cached_tf[i], cached_tf[j], idf_name='corpus_wc_cached')\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
